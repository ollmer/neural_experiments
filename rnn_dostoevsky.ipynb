{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Char RNN и Фёдор Михайлович Достоевский"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы обучем рекуррентную нейронную сеть генерить тексты в стиле Фёдора Михайловича Достоевского. Всё что её для этого понадобится - это способность предсказывать следующую букву для строки из уже имеющихся. Не стоит ожидать от сети осмысленных фраз и предложений, но правила композиции слов, общую структуру и настроение она улавливает довольно неплохо.\n",
    "\n",
    "Приведенный здесь результат работы получен за примерно 1 час обучение сети на ПК с видеокартой. Результат можно улучшить, увеличив время обучения или размер сети (её глубину или ширину слоёв).\n",
    "\n",
    "Итак, приступим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем все необходимые библиотеки, разрешаем бекенду Tensorflow увеличивать размер используемой GPU памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM,TimeDistributed, Embedding\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем текст, на котором будем обучаться и смотрим на его длину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 9469628\n"
     ]
    }
   ],
   "source": [
    "fname = 'dostoevsky.txt' #тексты основных романов Фёдора Михайловича, обьединенные в один файл\n",
    "text = open(fname, 'r', encoding='utf-8').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем простую статистику по загруженному тексту:\n",
    "    1. Число уникальных букв\n",
    "    2. Число уникальных пар букв (биграм)\n",
    "    3. Число уникальных троек букв (триграм)\n",
    "    4. Общее число слов и число уникальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars: 162\n",
      "unique bigrams: 3566\n",
      "unique trigrams: 26082\n",
      "word count: 1528727\n",
      "unique words: 165930\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('unique chars:', len(chars))\n",
    "char_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "bigrams = []\n",
    "for i in range(0, len(text)-1, 1):\n",
    "    bigrams.append(text[i] + text[i+1])\n",
    "bigrams = sorted(list(set(bigrams)))\n",
    "print('unique bigrams:', len(bigrams))\n",
    "bigram_idx = dict((c, i) for i, c in enumerate(bigrams))\n",
    "idx_bigram = dict((i, c) for i, c in enumerate(bigrams))\n",
    "\n",
    "trigrams = []\n",
    "for i in range(0, len(text)-2, 1):\n",
    "    trigrams.append(text[i] + text[i+1] + text[i+2])\n",
    "trigrams = sorted(list(set(trigrams)))\n",
    "print('unique trigrams:', len(trigrams))\n",
    "trigram_idx = dict((c, i) for i, c in enumerate(trigrams))\n",
    "idx_trigram = dict((i, c) for i, c in enumerate(trigrams))\n",
    "\n",
    "words = text.split()\n",
    "print('word count:', len(words))\n",
    "words = sorted(list(set(words)))\n",
    "print('unique words:', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать сеть будем мини-батчами, это значительно быстрее, чем подавать последовательности друг за другом.\n",
    "Для этого поделим весь наш текст на несколько равных последовательностей, число их будет равно числу батчей обучения.\n",
    "Как это делается, на примере батча размером 3 - в первый трек попадет текст от начала и до трети всей длины, во второй трек текст от 1/3 до 2/3 длины, а в третий - от 2/3 и до конца текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " только, что сын его, воспитывавшийся сначала у графа, а потом в лицее, окончил тогда курс наук девятнадцати лет от роду. Я написал об этом к Ихменевым, а также и о том, что князь очень любит своего сына, балует его, рассчитывает уже и теперь его будущность. Всё это я узнал от товарищей-студентов, знакомых молодому князю. В это-то время Николай Сергеич в одно прекрасное утро получил от князя письмо, чрезвычайно его удивившее...\n",
      "   Князь, который до сих пор, как уже упомянул я, ограничивался в сношениях с Николаем Сергеичем одной сухой, деловой перепиской, писал к нему теперь самым подробным, откровенным и дружеским образом о своих семейных обстоятельствах: он жаловался на своего сына, писал, что сын огорчает его дурным своим поведением; что, конечно, на шалости такого мальчика нельзя еще смотреть слишком серьезно (он видимо старался оправдать его), но что он решился наказать сына, попугать его, а именно: сослать ого на некоторое время в деревню, под присмотр Ихменева. Князь писал, что \n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024 # decrease if you have \"Failed to allocate memory\" error when start training\n",
    "track_size = len(text) // batch_size\n",
    "tracks = ['' for i in range(batch_size)]\n",
    "for i in range(0, track_size):\n",
    "    for track in range(batch_size):\n",
    "        tracks[track] += text[track * track_size + i]\n",
    "\n",
    "# Let's see what we've got\n",
    "print(tracks[4][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы будем работать только посимвольно, варианты с биграммами и триграммами оставим на будущее.\n",
    "Для начала соберем словари букв, биграмм и триграмм в списки. А затем определим функцию, которая будет преобразовывать переданный набор текстов в последовательности индексов для символов указанной длины.\n",
    "\n",
    "В нашем случае мы указываем длинну символа 1, т.е. использовать будем словарь отдельных букв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary done:  162\n"
     ]
    }
   ],
   "source": [
    "gram_idx = [char_idx, bigram_idx, trigram_idx]\n",
    "idx_gram = [idx_char, idx_bigram, idx_trigram]\n",
    "\n",
    "#converts to indexes of chars, bigrams, trigrams\n",
    "def grams(tracks, n=1):\n",
    "    indexed = []\n",
    "    for t in tracks:  \n",
    "        track = []\n",
    "        for i in range(0, len(t)-n+1, n):\n",
    "            gram = ''\n",
    "            for j in range(n):\n",
    "                gram += t[i+j]\n",
    "            idx = gram_idx[n-1][gram]\n",
    "            track.append(idx)\n",
    "        indexed.append(track)\n",
    "    return indexed\n",
    "\n",
    "indexed = grams(tracks, 1)\n",
    "vocab_size = len(gram_idx[0])\n",
    "print('Vocabulary done: ', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо разбить наши наборы индексов на батчи для обучения, а также подготовить целевые лейблы, которые сеть будет предсказывать.\n",
    "\n",
    "Наша сеть будет предсказывать следующую букву для последовательности, т.е. для фразы HELLO она получит на вход HELL и должна будет дать нам на выходе ELLO.\n",
    "\n",
    "Для предсказания индекса буквы нам необходимо преобразовать его в one-hot вектор - длина которого равна размеру нашего словаря, \n",
    "а во всех позициях кроме позиции с номером текущего индекса стоят нули. В позиции индекса же будет стоять единица. Например, для словаря из [E, H, L, O] длина словаря была бы 4, индекс буквы L - 3, а её one-hot вектор 0010.\n",
    "\n",
    "Также мы расставляем блоки из последовательностей длины N так, чтобы в каждом новом батче на позиции 1 стояла последовательность, продолжающая последовательность 1 из предыдущего батча, на позиции 2 - продолжающая текст позиции 2 предыдущего батча, и так далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 236544\n",
      "Number of training labels 236544\n",
      "Label sequence length 40\n",
      "Label character one-hot vector length 162\n"
     ]
    }
   ],
   "source": [
    "seq_len = 40 #length of sequence in a batch\n",
    "\n",
    "def onehot(n):\n",
    "    v = [0 for i in range(vocab_size)]\n",
    "    v[n] = 1\n",
    "    return v\n",
    "\n",
    "#build order for batches for stateful lstm\n",
    "def vectorize(tracks):\n",
    "    track_size = len(tracks[0])\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0, track_size - seq_len + 1, seq_len):\n",
    "        for t in tracks:\n",
    "            X.append(t[i:i + seq_len])\n",
    "            target = [onehot(c) for c in t[i+1:i + seq_len + 1]]\n",
    "            y.append(target)\n",
    "    return X, y\n",
    "        \n",
    "x,y = vectorize(indexed)\n",
    "print('Number of training samples', len(x))\n",
    "print('Number of training labels', len(y))\n",
    "print('Label sequence length', len(y[0]))\n",
    "print('Label character one-hot vector length', len(y[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приготовим нашу рекурентную сеть. В начале идёт embedding-слой, преобразующий индексы входной последовательности в dense вектор фиксированного размера. Затем несколько рекуррентных LSTM слоёв и один полносвязный слой с число выходов, равным размеру нашего словаря. В качестве loss-функции нам нужна кроссэнтропия, оптимизатором будем Adam и важно не забыть установить clipnorm - ограничение на размер градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1024, 40, 30)            4860      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1024, 40, 512)           1112064   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1024, 40, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1024, 40, 162)           83106     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (1024, 40, 162)           0         \n",
      "=================================================================\n",
      "Total params: 3,299,230\n",
      "Trainable params: 3,299,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cells = 512\n",
    "drop = 0.2\n",
    "embed = 30 # size of character embedding\n",
    "layers = 2\n",
    "lr = 0.01\n",
    "clip = 5.0 # gradient clipping to prevent exploding gradients\n",
    "stateful=True # maintain layer state between batches\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed, batch_input_shape=(batch_size, seq_len)))\n",
    "for l in range(layers):\n",
    "    model.add(LSTM(cells, return_sequences=True, stateful=stateful, dropout=drop))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = Adam(lr, clipnorm=clip)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, размер сети получился порядка 3.3 миллиона параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=5):\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
    "                                            patience=patience, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "    es = EarlyStopping('loss', verbose=1, min_delta=0.02, patience=patience, mode=\"min\")\n",
    "    return [learning_rate_reduction, es]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция sample позволит нам выбирать из выходов сети не просто самый вероятный символ, а получать случайный символ из распределения с заданными вероятностями. Параметр температуры позволяет регулировать степень строгости выбора, низкая температура приведет к более консервативной стратегии, в то время как с низкой температурой редкие символы будут выбираться немного чаще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=0.5):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша изначальная модель была построена исходя из указанного размера батча, а значит плохо подходит для работы на одной последовательности. Создадим её копию с размером батча 1 и перенесем туда веса обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictive_model(main_model): # change batch size to 1 for work with one sequence\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed, batch_input_shape=(1, seq_len)))\n",
    "    for l in range(layers):\n",
    "        model.add(LSTM(cells, return_sequences=True, stateful=stateful, dropout=drop))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    optimizer = Adam(lr, clipnorm=clip)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "    old_weights = main_model.get_weights()\n",
    "    model.set_weights(old_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция test будет генерировать новый символ по заданной строке, а затем заново подавать полученную строку на вход сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate new chars from model\n",
    "def test(model, l=500, seed = None, t=0.5):\n",
    "    start_from = np.random.randint(len(text)-seq_len)+seq_len\n",
    "    seed_string = text[start_from:start_from + seq_len*3] if seed is None else seed\n",
    "    print('\\n\\nSeed:  ', seed_string)\n",
    "    print('----')\n",
    "    sys.stdout.write(seed_string)\n",
    "    prmodel = predictive_model(model)\n",
    "    for i in range(l):\n",
    "        prmodel.reset_states()\n",
    "        padlen = (len(seed_string) // seq_len +1) * seq_len\n",
    "        seed_string = seed_string.rjust(padlen)[-seq_len*3:]\n",
    "        test_tracks = [seed_string]\n",
    "        tidx = grams(test_tracks)\n",
    "        xt, _ = vectorize(tidx)\n",
    "        preds = prmodel.predict(np.array(xt), batch_size=1, verbose=0)\n",
    "        preds = preds[-1][-1] # last symbol of last sequence\n",
    "        next_item = idx_char[sample(preds, t)]\n",
    "        seed_string = seed_string + next_item\n",
    "        sys.stdout.write(next_item)\n",
    "        sys.stdout.flush()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришло время обучить сеть. Попробуем делать это на протяжении 50 итераций, периодически (раз в 3 итерации) оценивая качество сгенерированного сетью текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 196s - loss: 3.3098   \n",
      "\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 188s - loss: 3.1676   \n",
      "\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 191s - loss: 2.5591   \n",
      ">>>  икальным объяснением, несмотря на то что дело плевое; я знаю его еще с Петербурга. К тому же весь анекдот делает только \n",
      "----\n",
      "икальным объяснением, несмотря на то что дело плевое; я знаю его еще с Петербурга. К тому же весь анекдот делает только на не воглану и вот двадь не сопривила не на прокоть пробовореться на солать не могда уго всего же самовеле дервать,  потодал\n",
      " что старет придорил отанила спа не прогость же того и не сот отводил все ста стастве. Прегавове,  скоронить е всё логда на с нимененно послей на проемала не не стольто вы мне мни сам, кня на старате телова пословаеть так на на смество миже все преседь слуго все в неста не сами призчите вот, не на тогда не закорорно как трязь потисту сопросенить лестольно из семи его на с\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 186s - loss: 2.0483   \n",
      "\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 190s - loss: 1.8013   \n",
      "\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 190s - loss: 1.6861   \n",
      ">>>   вдруг неожиданно.\n",
      "   - Как тем хуже?\n",
      "   - Хуже.\n",
      "   - Не понимаю.\n",
      "   - Друг мой, друг мой, ну пусть в Сибирь, в Архангел\n",
      "----\n",
      " вдруг неожиданно.\n",
      "   - Как тем хуже?\n",
      "   - Хуже.\n",
      "   - Не понимаю.\n",
      "   - Друг мой, друг мой, ну пусть в Сибирь, в Архангела Ивановна. То не по своего подсудим на дворе, что так, все все хоть положения и все это было вопросы всё просто под восторгами на него на вами спросил в говорить и в этом вашим с длинным себя. Вы вы ответил в демовым столько не могла какого не верите служал же довольно под всех совершенно закричала, что только было вы в комнате в нем до всеми продолжал и вдруг продолжал было не было образом деле не почему-то с первого не знал, вот тогда уж не знаю, точно так ли сильно в ней положительно всей не\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 188s - loss: 1.6235   \n",
      "\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 188s - loss: 1.5817   \n",
      "\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 189s - loss: 1.5523   \n",
      ">>>  в монастырские ворота пешком. Кроме Федора Павловича, остальные трое кажется никогда не видали никакого монастыря, а Миу\n",
      "----\n",
      "в монастырские ворота пешком. Кроме Федора Павловича, остальные трое кажется никогда не видали никакого монастыря, а Миусья от дверь обратил весь не полицей, слышал и с тобой на своей нетерпением про себя навсегда в самом долго и получил на того, которого же со столу просто под воротились к деревне, то есть до сих в креста, но не в полу примерника и не потому что тотчас же было не мог подле после него с неестественное все это самовольно и во всем доме проговорил с нелепый и и ответила в каком-то любопытством своего например, что всё равно не только и от после последней стола. Вот по свою для него последнее сторон\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 190s - loss: 1.5294   \n",
      "\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 193s - loss: 1.5108   \n",
      "\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 175s - loss: 1.4962   \n",
      ">>>  чал и долго обдумывал.\n",
      "   -- Штука в том: я задал себе один раз такой вопрос: что если бы, например, на моем месте случи\n",
      "----\n",
      "чал и долго обдумывал.\n",
      "   -- Штука в том: я задал себе один раз такой вопрос: что если бы, например, на моем месте случилось и даже до сих пор не было уже, чтобы принял его на \"собственных сил за красного стороны, по приходить явился на покойным волнением уверена нахмурился и что он все до рассказывался к нему на полным положении. Пойдемте, она заплачения и не мог от всех пред том и уже не знает и может, с негодованиями человеком, по крайней больше и открылась от меня и умел в болезни послали. Он не простить на меня в однем доме подумали его. Если бы он в том, что вы из него он был в горячее и подле обойхнулся в \n",
      "Iteration 13\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 133s - loss: 1.4842   \n",
      "\n",
      "Iteration 14\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 133s - loss: 1.4732   \n",
      "\n",
      "Iteration 15\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 132s - loss: 1.4645   \n",
      ">>>   Стоило ли это теперь хоть какой-нибудь тревоги, в свою очередь, хотя какого-нибудь даже внимания! Он стоял, читал, слуш\n",
      "----\n",
      " Стоило ли это теперь хоть какой-нибудь тревоги, в свою очередь, хотя какого-нибудь даже внимания! Он стоял, читал, слушают из всех пор не потом и старика и бросились о том, что он Лебядкина была сел в комнате с нею с дверью собственные вечер в господин.\n",
      "   -- Нет, не знаю на красного любовь этого была от него в самом великодушным предмете, и не верите меня с тобой, и не подумал в комнате, но он высказал все два стороны совсем не случилось в голову. Вы тоже после принести и не потому что просто не хочу! -- спросил он вдруг в ту же словах на меня на него и не видел и уже не буду повернулась было слевение. Нарочно \n",
      "Iteration 16\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 131s - loss: 1.4558   \n",
      "\n",
      "Iteration 17\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 132s - loss: 1.4484   \n",
      "\n",
      "Iteration 18\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 132s - loss: 1.4423   \n",
      ">>>   мне было почему-то ужасно совестно заговаривать о Полине; он же сам ни слова о ней не спросил. Я рассказал ему про бабу\n",
      "----\n",
      " мне было почему-то ужасно совестно заговаривать о Полине; он же сам ни слова о ней не спросил. Я рассказал ему про бабушкой и познакомился образованным под всего последнею голову со голову. Но не понял гостя смотрела на него и про то не обернулся и между тем и больше настоящий и все равно обратилась на два доктор и на положения и не получил на него увидеть на этот раз ответил и должно быть, потому что в этот раз так сказать, и уж не прошептал бы не понять, что она всегда все спокойно прокурор вздрагал за своей руку. Он обойтись, как бы сказать, и он пристально поступила на меня наконец, подхватив перепалительно \n",
      "Iteration 19\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 132s - loss: 1.4355   \n",
      "\n",
      "Iteration 20\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 133s - loss: 1.4321   \n",
      "\n",
      "Iteration 21\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 134s - loss: 1.4265   \n",
      ">>>  ра кончить!\n",
      "   -- Объяснитесь, Наталья Николаевна, -- подхватил князь, -- убедительно прошу вас! Я уже два часа слышу об\n",
      "----\n",
      "ра кончить!\n",
      "   -- Объяснитесь, Наталья Николаевна, -- подхватил князь, -- убедительно прошу вас! Я уже два часа слышу обо всем даже теперь в этом обществе и слушать, что он совсем не знал \"на нее\". Но все могу от него была в том, что назад на него с первого взгляда по крайней мере всегда так всегда подлецой, что не подробно стал в таком половину и с нею ни за что и не сказал его с тем и стало быть все время прошло подумал, что только что она была только хоть и положительно стала допустить глазами, -- подумал он вдруг он мелькнула и ответила в своей месте в беспокойстве в дела. Поверьте, что и может быть, не думаю\n",
      "Iteration 22\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 132s - loss: 1.4226   \n",
      "\n",
      "Iteration 23\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 131s - loss: 1.4182   \n",
      "\n",
      "Iteration 24\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 129s - loss: 1.4148   \n",
      ">>>  ила Авдотья Романовна.\n",
      "   -- Вы думаете, -- с жаром продолжала Пульхерия Александровна, -- его бы остановили тогда мои с\n",
      "----\n",
      "ила Авдотья Романовна.\n",
      "   -- Вы думаете, -- с жаром продолжала Пульхерия Александровна, -- его бы остановили тогда мои старухи не брать предложение просто подумал, что по крайней мере в моем деле и с тем на него гордости в другой раз, что он не потому в безородном отца в первый раз был не подумали. Пусть на меня показалось в недоумении на ней и вышел к нему. Потому что так на него надо было не надо было сказать на делам и подсудимого и в подлец свои лет в половину в то же моей себе его с первого последнее пользу на меня в показать себя с свою неужели и в нем повторять общество. Он понял теперь в глаза от двух под\n",
      "Iteration 25\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 133s - loss: 1.4118   \n",
      "\n",
      "Iteration 26\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 178s - loss: 1.4093   \n",
      "\n",
      "Iteration 27\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 135s - loss: 1.4065   \n",
      ">>>  рены, благодушнейший, искреннейший и благороднейший князь, -- вскричал Лебедев в решительном вдохновении, -- будьте увер\n",
      "----\n",
      "рены, благодушнейший, искреннейший и благороднейший князь, -- вскричал Лебедев в решительном вдохновении, -- будьте уверяли ваше минуты, -- как тот с нею моим добрым с лестнице. И вот я не обращаюсь, что я ведь не отвечал и пристально поступил и понял, что я только уж как я не стал все и так по лежать на восторге в городе и по крайней мере даже не со мной. Но он ведь только не имел в таком случае и при этом странной стороны, но вы его даже не поставить. А он потому что я еще не понимаешь, что я как бы не знаю, что он в нем долгими с тобой в перед нею и не видал его в руках и последних старуха и все это удивлялись\n",
      "Iteration 28\n",
      "Epoch 1/1\n",
      "236544/236544 [==============================] - 137s - loss: 1.4029   \n",
      "\n",
      "Iteration 29\n",
      "Epoch 1/1\n",
      " 50176/236544 [=====>........................] - ETA: 104s - loss: 1.4088"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-40b189af2ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 51):\n",
    "    print('\\nIteration', iteration)\n",
    "    model_name = 'char_%s_%d_%d_%.1f_%d.h5' % (fname, layers, cells, drop, iteration)\n",
    "    history=model.fit(\n",
    "        np.array(x), np.array(y), \n",
    "        batch_size=batch_size, \n",
    "        epochs=1, \n",
    "        verbose=1, \n",
    "        shuffle=False,\n",
    "        callbacks=get_callbacks(filepath=model_name)\n",
    "    )\n",
    "    model.save_weights(model_name, overwrite=True)\n",
    "    model.reset_states()\n",
    "    if iteration%3 == 0:\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По логу обучения хорошо видно, как сеть шаг за шагом усваивает всё более и более сложные закономерности исходного текста. Вначале это проблемы между словами, типичные слоги, отделение предложений точкой. Затем слова становятся всё более и более похожими на нормальный русский язык, сеть учится писать имена и диалоги, разделенные отступами и тире. Видно, как сеть начинает использовать и другие знаки препинания, строить сложные предложения, выводить непрямую речь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем посмотреть как влияет температура семплинга на выводимый моделью текст. Используем для этого одну и ту же начальную последовательность и посмотрим на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Seed:   У нас в Малом зале до сих пор проходят\n",
      "----\n",
      "У нас в Малом зале до сих пор проходят с ним с тобой и подозревали и подозревали и при всех столь и под конец просто подозрения и просто подозревали и при своей стороны и принять своего простодушного старика и подозревали и просто подозревали и подозревали и под конец в своем положении и принять в себе старика, но в том, что он всегда п\n",
      "\n",
      "Seed:   У нас в Малом зале до сих пор проходят\n",
      "----\n",
      "У нас в Малом зале до сих пор проходят на свою разом и не после прежнего правда с тревожностью, выразился и смотрел на положении. Но просто отвечала она принять меня и сказал его и пред нею, как бы во всех своего проклятий принес в картину и стал простодушное ветром и воздух не понимаю, что не давать предстоящего и судорога. Она убил с \n",
      "\n",
      "Seed:   У нас в Малом зале до сих пор проходят\n",
      "----\n",
      "У нас в Малом зале до сих пор проходят картины. Теперь сейчас они остановившись пошле дорогу совсем и почти неожиданное  своего  затрастно   на  собой  в  том,  чтобы  не\n",
      "  сказали его ответ к нему прочтить виде и деньги в руках голова  -  учительно  и\n",
      "  старику с каким-то полячной столы погросить, но на него. -- Всё больше-то и распоря"
     ]
    }
   ],
   "source": [
    "seed = \"У нас в Малом зале до сих пор проходят\"\n",
    "test(model, 300, seed, 0.1)\n",
    "test(model, 300, seed, 0.5)\n",
    "test(model, 300, seed, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При низких температура модель начинает застревать в каких-то внутренних циклах и колеблется около одной и той же темы. С ростом температуры разнообразие текста повышается, но с какого-то момента всё больше слов сеть \"придумывает\" и текст становится слегка бредовым. Слова эти, тем немнее, построены по правилам русского языка и выглядят очень походими на настоящие."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
